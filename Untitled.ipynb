{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "from data.dataloader import itemDataset,ToTensor,collate_fn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from model.model_builder import build_model #still need some little modify\n",
    "from model.util.optimizers import build_optim\n",
    "from model.util.Logger import logger,init_logger  #finish\n",
    "from model.util.saver import build_model_saver  #finish\n",
    "from model.util import Report_manager\n",
    "\n",
    "import torch.nn as nn\n",
    "from model import Trainer\n",
    "import opts\n",
    "\n",
    "def _check_save_model_path(opt):\n",
    "    save_model_path = os.path.abspath(opt.save_model)\n",
    "    model_dirname = os.path.dirname(save_model_path)\n",
    "    if(not os.path.exists(model_dirname)):\n",
    "        os.makedirs(model_dirname)\n",
    "\n",
    "def training_opt_postprocessing(opt):\n",
    "    if(torch.cuda.is_available() and not opt.gpuid):\n",
    "        logger.info(\"you should use gpu to train the model.\")\n",
    "    \n",
    "    if opt.seed > 0:\n",
    "        torch.manual_seed(opt.seed)\n",
    "        # this one is needed for torchtext random call (shuffled iterator)\n",
    "        # in multi gpu it ensures datasets are read in the same order\n",
    "        random.seed(opt.seed)\n",
    "        # some cudnn methods can be random even after fixing the seed\n",
    "        # unless you tell it to be deterministic\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    if opt.gpuid:\n",
    "        torch.cuda.set_device(opt.device_id)\n",
    "        if opt.seed > 0:\n",
    "            # These ensure same initialization in multi gpu mode\n",
    "            torch.cuda.manual_seed(opt.seed)\n",
    "    return opt\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.src_word_vec_size=256\n",
    "opts.tar_word_vec_size=256\n",
    "\n",
    "opts.feat_merge='sum'\n",
    "opts.feat_vec_size=256\n",
    "\n",
    "opts.encoder_type='transformer'\n",
    "opts.decoder_type='transformer'\n",
    "opts.replace=True\n",
    "opts.num_layer=3\n",
    "opts.enc_layer=6\n",
    "opts.dec_layer=3\n",
    "opts.model_dim=256\n",
    "opts.nin_dim_en=1024\n",
    "opts.nin_dim_de=512\n",
    "\n",
    "\n",
    "opts.dropout=0.1\n",
    "\n",
    "opts.global_attention='general'\n",
    "\n",
    "opts.self_attn_type=\"scaled_dot\"\n",
    "opts.num_head=8\n",
    "\n",
    "opts.gpuid=0\n",
    "opts.seed=0\n",
    "opts.log_file = \"./logger\"\n",
    "opts.save_model = \"./sssss/output1\"\n",
    "opts.show = True\n",
    "opts.train_from = \"./ch_en/model_save/step_300000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-29 02:46:21,001 INFO loading checkpoint from ./ch_en/model_save/step_300000.pt]\n",
      "[2018-10-29 02:46:21,332 INFO source size:32760]\n",
      "[2018-10-29 02:46:21,333 INFO target size:32751]\n"
     ]
    }
   ],
   "source": [
    "opt = training_opt_postprocessing(opt)\n",
    "init_logger(opt)\n",
    "\n",
    "if(opt.train_from):\n",
    "    logger.info('loading checkpoint from {0}'.format(opt.train_from))\n",
    "    device = torch.device('cpu')\n",
    "    checkpoint = torch.load(opt.train_from,map_location=device)\n",
    "\n",
    "    model_opt = checkpoint['opt']\n",
    "else:\n",
    "    checkpoint = None\n",
    "    model_opt = opt\n",
    "\n",
    "data_token = dict()\n",
    "\n",
    "for ttype in ['source','target']:\n",
    "    data_token[ ttype ] = dict()\n",
    "    with open('./ch_en/subword.{0}'.format(ttype)) as f_in:\n",
    "        for j,word in enumerate(f_in):\n",
    "            data_token[ttype][word.strip()[1:-1]] = j\n",
    "\n",
    "logger.info(\"source size:{0}\".format(len(data_token['source'])))\n",
    "logger.info(\"target size:{0}\".format(len(data_token['target'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.nin_dim_en = model_opt.nin_dim\n",
    "model_opt.nin_dim_de = model_opt.nin_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-29 02:46:24,435 INFO start build model]\n",
      "[2018-10-29 02:46:24,436 INFO Building model...]\n",
      "[2018-10-29 02:46:24,713 INFO finish build encoder]\n",
      "[2018-10-29 02:46:25,077 INFO finish build decoder]\n",
      "[2018-10-29 02:46:25,082 INFO loading model weight from checkpoint]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size will be 36313583 13158400 23155183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-29 02:46:28,962 INFO the model is now in the cuda mode]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(\n",
       "      (word_emb): Embedding(32760, 256, padding_idx=0)\n",
       "      (pos_emb): Embedding(128, 256)\n",
       "      (drop): Dropout(p=0.1)\n",
       "    )\n",
       "    (self_attention): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (layer_norm): LayerNorm()\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (layer_norm): LayerNorm()\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (layer_norm): LayerNorm()\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (layer_norm): LayerNorm()\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (layer_norm): LayerNorm()\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (layer_norm): LayerNorm()\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(\n",
       "      (word_emb): Embedding(32751, 256, padding_idx=0)\n",
       "      (pos_emb): Embedding(128, 256)\n",
       "      (drop): Dropout(p=0.1)\n",
       "    )\n",
       "    (transformer_layer): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm()\n",
       "        (layer_norm_2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm()\n",
       "        (layer_norm_2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm()\n",
       "        (layer_norm_2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm()\n",
       "        (layer_norm_2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm()\n",
       "        (layer_norm_2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_key): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_value): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (feed_forward): Network_In_Network(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (dropout_1): Dropout(p=0.1)\n",
       "          (dropout_2): Dropout(p=0.1)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm()\n",
       "        (layer_norm_2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm()\n",
       "    (linear): Linear(in_features=256, out_features=32751, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"start build model\")\n",
    "model = build_model(model_opt,opt,data_token,checkpoint)\n",
    "model.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32760, 256, padding_idx=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.embedding.word_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = model.encoder.embedding.word_emb.weight.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tag = weight[2:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0119, -0.0048,  0.0120,  ...,  0.0019,  0.0041, -0.0121],\n",
       "        [-0.0133, -0.0057,  0.0032,  ..., -0.0081,  0.0128, -0.0076],\n",
       "        [-0.0081, -0.0074, -0.0124,  ...,  0.0126,  0.0095,  0.0067],\n",
       "        ...,\n",
       "        [-0.0071,  0.0076, -0.0041,  ...,  0.0003,  0.0055, -0.0040],\n",
       "        [ 0.0324, -0.0099, -0.0759,  ...,  0.0980,  0.0066,  0.3821],\n",
       "        [-0.0217, -0.0282,  0.0952,  ...,  0.0768,  0.0294, -0.1290]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_word = torch.cat((weight[:2],weight[12:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0038, -0.0061, -0.0112,  ...,  0.0116, -0.0034,  0.0118],\n",
       "        [ 0.0390, -0.0318, -0.0893,  ...,  0.2093,  0.0677,  0.0430],\n",
       "        [-0.0004, -0.0055,  0.0226,  ...,  0.0302,  0.0141, -0.0224],\n",
       "        ...,\n",
       "        [ 0.0135,  0.0132,  0.0113,  ...,  0.0027, -0.0096,  0.0108],\n",
       "        [ 0.0067, -0.0037,  0.0030,  ...,  0.0097, -0.0113, -0.0037],\n",
       "        [ 0.0065,  0.0116,  0.0008,  ...,  0.0042, -0.0024,  0.0068]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.embedding.word_emb = nn.Embedding(32750,256,padding_idx=0)\n",
    "model.encoder.embedding.word_emb.weight = nn.Parameter(weight_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.embedding.tag_emb = nn.Embedding(10,256)\n",
    "model.encoder.embedding.tag_emb.weight = nn.Parameter(weight_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0119, -0.0048,  0.0120,  ...,  0.0019,  0.0041, -0.0121],\n",
       "        [-0.0133, -0.0057,  0.0032,  ..., -0.0081,  0.0128, -0.0076],\n",
       "        [-0.0081, -0.0074, -0.0124,  ...,  0.0126,  0.0095,  0.0067],\n",
       "        ...,\n",
       "        [-0.0071,  0.0076, -0.0041,  ...,  0.0003,  0.0055, -0.0040],\n",
       "        [ 0.0324, -0.0099, -0.0759,  ...,  0.0980,  0.0066,  0.3821],\n",
       "        [-0.0217, -0.0282,  0.0952,  ...,  0.0768,  0.0294, -0.1290]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.embedding.tag_emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (word_emb): Embedding(32750, 256, padding_idx=0)\n",
       "  (pos_emb): Embedding(128, 256)\n",
       "  (drop): Dropout(p=0.1)\n",
       "  (tag_emb): Embedding(10, 256)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()\n",
    "\n",
    "#check for dataset_setting\n",
    "checkpoint = {\n",
    "    \"model\" : model_state_dict,\n",
    "    \"opt\":checkpoint['opt'],\n",
    "    'optim':checkpoint['optim'],\n",
    "    \"reporter\":checkpoint['reporter']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint,'./total/total_pretrain.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.load('./total/total_pretrain.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
